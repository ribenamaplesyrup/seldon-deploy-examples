{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinanet Deployment and Video Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have wrapped Retinanet and pushed your container to Dockerhub you are ready to create the deployment and run inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seldon_deploy_sdk import Configuration, ApiClient, SeldonDeploymentsApi, BatchJobsApi, BatchDefinition\n",
    "from seldon_deploy_sdk.auth import OIDCAuthenticator\n",
    "import requests\n",
    "\n",
    "SD_IP = \"\"\n",
    "username = \"\"\n",
    "password = \"\"\n",
    "\n",
    "config = Configuration()\n",
    "config.host = f\"http://{SD_IP}/seldon-deploy/api/v1alpha1\"\n",
    "\n",
    "config.oidc_client_id = \"sd-api\"\n",
    "config.oidc_client_secret = \"sd-api-secret\"\n",
    "config.oidc_server = f\"http://{SD_IP}/auth/realms/deploy-realm\"\n",
    "\n",
    "def auth():\n",
    "    auth = OIDCAuthenticator(config)\n",
    "    config.access_token = auth.authenticate(username, password)\n",
    "    api_client = ApiClient(config)\n",
    "    return api_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the deployment manifest, replacing `CONTAINER_IMAGE` with your own container image name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER_IMAGE = \"\"\n",
    "DEPLOYMENT_NAME = \"retinanet\"\n",
    "NAMESPACE = \"test\"\n",
    "\n",
    "CPU_REQUESTS = \"1\"\n",
    "MEMORY_REQUESTS = \"1Gi\"\n",
    "\n",
    "CPU_LIMITS = \"1\"\n",
    "MEMORY_LIMITS = \"2Gi\"\n",
    "\n",
    "mldeployment = {\n",
    "    \"kind\": \"SeldonDeployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"namespace\": NAMESPACE,\n",
    "        \"labels\": {\n",
    "            \"fluentd\": \"true\"\n",
    "        }\n",
    "    },\n",
    "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha2\",\n",
    "    \"spec\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"annotations\": {\n",
    "            \"seldon.io/engine-seldon-log-messages-externally\": \"true\"\n",
    "        },\n",
    "        \"protocol\": \"seldon\",\n",
    "        \"transport\": \"rest\",\n",
    "        \"predictors\": [\n",
    "            {\n",
    "                \"componentSpecs\": [\n",
    "                    {\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                                    \"image\": CONTAINER_IMAGE,\n",
    "                                    \"resources\": {\n",
    "                                        \"requests\": {\n",
    "                                            \"cpu\": CPU_REQUESTS,\n",
    "                                            \"memory\": MEMORY_REQUESTS\n",
    "                                        },\n",
    "                                        \"limits\": {\n",
    "                                            \"cpu\": CPU_LIMITS,\n",
    "                                            \"memory\": MEMORY_LIMITS\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"name\": \"default\",\n",
    "                \"replicas\": 1,\n",
    "                \"traffic\": 100,\n",
    "                \"graph\": {\n",
    "                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                    \"endpoint\": {\n",
    "                        \"type\": \"REST\"\n",
    "                    },\n",
    "                    \"parameters\": [],\n",
    "                    \"children\": [],\n",
    "                    \"logger\": {\n",
    "                        \"mode\": \"all\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"status\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch your deployment: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_api = SeldonDeploymentsApi(auth())\n",
    "deployment_api.create_seldon_deployment(namespace=NAMESPACE, mldeployment=mldeployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy video to MinIO\n",
    "\n",
    "We will now copy our video data to MinIO installed in the K8s cluster running Seldon. If you have MinIO installed, open up a seperate terminal and port-forward to MinIO with the following command:\n",
    "\n",
    "`!kubectl port-forward -n minio-system svc/minio 8090:9000`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import test video: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import matplotlib.pyplot as plt\n",
    "frames = torchvision.io.read_video(filename= \"input/video1.mp4\")\n",
    "frames[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the video contains 362 frames of size 540x960. The frames consist of several people riding motorcycles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test batch on a smaller range of frames (10 frames). Tensors will be saved to a text file which will be pushed to MinIO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"images.txt\", \"w\")\n",
    "for frame in frames[0][0:9]:\n",
    "    textfile.write(str(frame.tolist()) + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mc cp images.txt minio/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run batch inference, writing the results to `output-images-{{workflow.name}}.txt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKFLOW = {\n",
    "    \"batchDataType\": \"data\",\n",
    "    \"batchMethod\": \"predict\",\n",
    "    \"batchRetries\": \"3\",\n",
    "    \"batchTransportProtocol\": \"rest\",\n",
    "    \"batchWorkers\": \"15\",\n",
    "    \"inputData\": \"s3://data/images.txt\",\n",
    "    \"objectStoreSecretName\": \"seldon-job-secret\",\n",
    "    \"outputData\": \"s3://data/output-images-{{workflow.name}}.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_api = BatchJobsApi(auth())\n",
    "batch_api.create_seldon_deployment_batch_job(name=DEPLOYMENT_NAME, namespace=NAMESPACE, workflow=WORKFLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME='<workflowName>'\n",
    "\n",
    "batch_api = BatchJobsApi(auth())\n",
    "batch_api.get_deployment_batch_job(name=DEPLOYMENT_NAME, namespace=NAMESPACE, job_name=JOB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\": {\"names\": [\"t:0\", \"t:1\"], \"ndarray\": [[[183, 305, 263, 420], [893, 68, 947, 158]], [\"person\", \"person\"]]}, \"meta\": {\"requestPath\": {\"retinanet-container\": \"seangreaves/pytorch:0.1\"}}}\r\n",
      "{\"data\": {\"names\": [\"t:0\", \"t:1\", \"t:2\"], \"ndarray\": [[[195, 301, 266, 417], [184, 344, 281, 451], [893, 68, 946, 158]], [\"person\", \"motorcycle\", \"person\"]]}, \"meta\": {\"requestPath\": {\"retinanet-container\": \"seangreaves/pytorch:0.1\"}}}\r\n",
      "{\"data\": {\"names\": [\"t:0\", \"t:1\", \"t:2\"], \"ndarray\": [[[206, 292, 279, 400], [195, 343, 295, 445], [894, 68, 945, 159]], [\"person\", \"motorcycle\", \"person\"]]}, \"meta\": {\"requestPath\": {\"retinanet-container\": \"seangreaves/pytorch:0.1\"}}}\r\n",
      "{\"data\": {\"names\": [\"t:0\", \"t:1\", \"t:2\"], \"ndarray\": [[[213, 287, 283, 396], [204, 334, 302, 437], [891, 70, 937, 156]], [\"person\", \"motorcycle\", \"person\"]]}, \"meta\": {\"requestPath\": {\"retinanet-container\": \"seangreaves/pytorch:0.1\"}}}\r\n",
      "{\"data\": {\"names\": [\"t:0\", \"t:1\", \"t:2\"], \"ndarray\": [[[221, 281, 285, 391], [211, 319, 308, 429], [890, 70, 937, 157]], [\"person\", \"motorcycle\", \"person\"]]}, \"meta\": {\"requestPath\": {\"retinanet-container\": \"seangreaves/pytorch:0.1\"}}}\r\n",
      "{\"data\": {\"names\": [\"t:0\", \"t:1\", \"t:2\"], \"ndarray\": [[[236, 270, 304, 382], [230, 320, 323, 415], [891, 70, 939, 157]], [\"person\", \"motorcycle\", \"person\"]]}, \"meta\": {\"requestPath\": {\"retinanet-container\": \"seangreaves/pytorch:0.1\"}}}\r\n",
      "{\"data\": {\"names\": [\"t:0\", \"t:1\", \"t:2\"], \"ndarray\": [[[245, 262, 308, 370], [237, 296, 329, 407], [890, 70, 937, 157]], [\"person\", \"motorcycle\", \"person\"]]}, \"meta\": {\"requestPath\": {\"retinanet-container\": \"seangreaves/pytorch:0.1\"}}}\r\n",
      "{\"data\": {\"names\": [\"t:0\", \"t:1\", \"t:2\", \"t:3\"], \"ndarray\": [[[244, 286, 336, 401], [250, 261, 319, 373], [819, 442, 909, 539], [890, 70, 938, 158]], [\"motorcycle\", \"person\", \"person\", \"person\"]]}, \"meta\": {\"requestPath\": {\"retinanet-container\": \"seangreaves/pytorch:0.1\"}}}\r\n",
      "{\"data\": {\"names\": [\"t:0\", \"t:1\", \"t:2\", \"t:3\"], \"ndarray\": [[[261, 254, 329, 356], [811, 432, 909, 537], [254, 291, 339, 393], [893, 70, 948, 162]], [\"person\", \"person\", \"motorcycle\", \"person\"]]}, \"meta\": {\"requestPath\": {\"retinanet-container\": \"seangreaves/pytorch:0.1\"}}}\r\n"
     ]
    }
   ],
   "source": [
    "!mc cat minio/data/output-images-<workflowName>.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
